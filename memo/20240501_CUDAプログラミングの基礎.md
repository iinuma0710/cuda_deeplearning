# CUDA プログラミングの基礎
ここでは、CUDA C++ による基本的なコードの記述方法や、GPU の内部構造について学びます。


## カーネル (Kernel)
CUDA C++ では、GPU 上で実行する関数をカーネル (Kernel) と呼びます。
以下は、2つのベクトル ```A``` と ```B``` を足し合わせて、```C``` に格納するコードを示しています。

```cpp
// カーネルの定義
__global__ void VecAdd(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}

int main()
{
    // カーネルの呼び出し
    VecAdd<<<1, N>>>(A, B, C);
}
```

C++ のコード中で、カーネルは ```__global__``` 宣言を用いて定義されます。
```thredIdx``` はカーネル内で利用可能な変数です。
そして、```<<<...>>>``` で実行するスレッド数などを指定して、CPU 側のコードから呼び出します。
実際には、GPU 上のメモリ確保や解放、CPU とのデータ送受信など、GPU を利用するためには、いくつかコードを追加する必要があります。
それらについて学ぶ前に、GPU の階層構造について見ていきます。

## 演算器の階層構造

### スレッド (Thread)
スレッドは GPU で演算を実行する際の最小単位です。
1次元から3次元のインデックスを持ち、カーネル内でそれぞれ ```threadIdx.x```、```threadIdx.y```、```threadIdx.z``` として参照されます。
次のコードは、$N \times N$ 行列の和を計算するコードです。

```cpp
__global__ void VecAdd(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    int j = threadIdx.y
    C[i][j] = A[i][j] + B[i][j];
}

int main()
{
    int numBlocks = 1;
    dim3 threadsPerBlock(N, N);
    VecAdd<<<numBlocks, threadsPerBlock>>>(A, B, C);
}
```

スレッドのまとまりをブロックと呼び、```<<<...>>>``` の1つ目の要素にブロック数を指定します。
```dim3``` はスレッドのインデックスを表す型で、```threadPerBlock``` で